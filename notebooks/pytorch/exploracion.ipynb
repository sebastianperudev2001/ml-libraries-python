{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch\n",
    "\n",
    "- Open source library for deep learning applications.\n",
    "- Originated from Torch Library. \n",
    "- 2 essential features:\n",
    "    1. **Tensor Computing**: Similar to NumPy arrays, Pytorch provides **Tensors**, which are generalizations of matrices and serves as basic building blocks of Deep Learning Algorithms. \n",
    "    2. **Automatic Differentiation**: In Deep Learning, we need to adjust parameters (**gradients**). \n",
    "\n",
    "## Pytorch ecosystem\n",
    "\n",
    "1. **Torchvision**: Datasets, models and transforms for computer vision.\n",
    "2. **Torchtext**: NLP. Dataloaders, vocabularies and common text transformations --> Simplify preprocessing pipeline for text-based applications.\n",
    "3. **Torchaudio**: Dataset, model architectures and audio transformations.\n",
    "4. **ONNX Integration**: Ensures interoperability between AI frameworks --> Allow users to transition their models to other platforms.\n",
    "5. **Captum**: Offer model interpretability and understanding tools for deep learning.\n",
    "6. **Ecosystem tools**: Albumentations (image augmentations, lighting), etc.\n",
    "\n",
    "## Basic Elements:\n",
    "\n",
    "1. **Tensors**: Fundamental data structure. \n",
    "2. **Computational Graph**: Define and modify the graph on the go.\n",
    "3. **Autograd module**: Automatic differentiation for all operations on tensors (useful in backpropagation). \n",
    "4. **Neural Network Module**: Design and train neural network. \n",
    "    - Pre defined layers.\n",
    "    - Loss functions.\n",
    "    - Optimizations routines.\n",
    "5. **Optim module**: Optimization routines, gradient descent variations. \n",
    "6. **Utilities**: Data handling to performance profiling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch import nn #neural network\n",
    "from pytorch import optim #optimization\n",
    "from pytorch import autograd # automatic differentiation\n",
    "from pytorch import torchvision # computer vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loader\n",
    "\n",
    "- **Batch processing**: Automates mini-batch creation for frequent model weight updates.\n",
    "- **Shuffling**: Ordenar al azar\n",
    "- **Parallel Loading** Usa subprocesos multiples para cargar la data, optimizando el uso del CPU.\n",
    "- **Custom Data Handling**: Permite utilizar datasets propios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4, 2])\n",
      "tensor([1, 5])\n",
      "tensor([3])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "# Create a sample dataset\n",
    "data = [1, 2, 3, 4, 5]\n",
    "dataset = CustomDataset(data)\n",
    "\n",
    "# Create a data loader\n",
    "batch_size = 2\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Iterate over the data loader\n",
    "for batch in dataloader:\n",
    "    print(batch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use cases:\n",
    "\n",
    "1. Computer vision\n",
    "2. NLP\n",
    "3. Generative models \n",
    "4. Reinforcement learning\n",
    "5. Audio Processing\n",
    "6. Health care\n",
    "7. Autonomous Vehicules\n",
    "8. Finance\n",
    "9. Sistemas de recomendación\n",
    "10. Dispositivos perifericos\n",
    "\n",
    "# Beneficios\n",
    "\n",
    "1. Acelera la productividad de los desarrolladores.\n",
    "2. Fácil de aprender y sencillo de codificar\n",
    "3. Simplificadad y transparencia\n",
    "4. Fácil de debuggear\n",
    "5. Paralelismo de data\n",
    "\n",
    "# Pytorch vs Tensorflow: Cuando Pytorch gana\n",
    "\n",
    "1. Pytorch ofrece **dynamic computation graph** en comparación de la versión estático de Tensorflow. Esto consiste en definir mientras se ejecuta el modelo. \n",
    "2. Debug: Usa herramientas nativas de Pyhon para solucionar problemas.\n",
    "3. Research Friendliness: Mezclar modelos, probar nuevas arquitecturas, experimentar sin mucho problema."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
